<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Guy Gafni</title>

    <meta name="author" content="Guy Gafni">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N20KYCQTQ3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-N20KYCQTQ3');
</script>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Guy Gafni
                </p>
                <p style="text-align:center">
                  <a href="https://scholar.google.com/citations?user=PATfNhwAAAAJ&hl=en" style="font-size: 20px; font-style: normal !important;">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/gafniguy" style="font-size: 20px; font-style: normal !important;">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/gafniguy" style="font-size: 20px; font-style: normal !important;">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/guy-gafni/" style="font-size: 20px; font-style: normal !important;">LinkedIn</a>
                </p>
                <p>
                  I'm <strong>Co-founder and CTO at <a href="https://pipio.ai/">Pipio AI</a></strong>, where we're building foundation video model for talking humans. A video diffusion model with perfect lip sync, designed for video editing workflows.
                  <br>
                  <br>
                  Before that, I was a PhD candidate at the Technical University of Munich, <strong><a href="https://niessnerlab.org//">Visual Computing and AI Lab</a></strong>, where I was advised by Prof. Matthias Nie√üner (w/ Prof. Justus Thies) working on neural rendering, NeRFs, reconstruction and re-rendering of faces. 
                              </p>

                <p style="text-align:center; margin-top:8px;">
                  üìç Munich, Germany
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/portrait.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/portrait.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in 3D Computer Vision and generative AI, specifically in video generation and editing of humans. I prefer generating and looking at pixels over improving a metric, and appreciate the use of 3D priors. Lately I've been heavily working on video diffusion models. <br> 
                  <br>
                  In 2023 I did a research internship at Meta Reality Labs in Zurich, working on 4D multiview reconstruction of humans. My last couple of projects have been around audio-driven facial re-enactment, hyper-realistic human avatars, dubbing and lip-sync. In the past, with CNNs and GANs, now heavily focused on DiTs and flow-matching.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="edityourself_stop()" onmouseover="edityourself_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='edityourself_image'>
        <img src='images/edityourself.jpg' width=100%>
      </div>
      <img src='images/edityourself.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function edityourself_start() {
        document.getElementById('edityourself_image').style.opacity = "1";
      }

      function edityourself_stop() {
        document.getElementById('edityourself_image').style.opacity = "0";
      }
      edityourself_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://cautious-adventure-5ly6e9e.pages.github.io/">
      <span class="papertitle">EditYourself: Flexible Audio-Driven Generation and Manipulation of Talking Head Videos</span>
    </a>
    <br>
    John Flynn,
    Wolfgang Paier,
    Dimitar Dinev,
    Sam Nhut Nguyen,
    Hayk Poghosyan,
    Sandipan Banerjee,
    <strong>Guy Gafni</strong>
    <br>
    <em>ArXiv</em>, 2026
    <br>
    <a href="https://cautious-adventure-5ly6e9e.pages.github.io/">project page</a>
    /
    <a href="#">arXiv</a>
    <p></p>
    <p>
    EditYourself is a diffusion-based video editing model for talking heads, enabling transcript-driven lip-syncing, insertion, removal and retiming of speech while preserving identity and visual fidelity.
    </p>
  </td>
</tr>

<tr onmouseout="semantify_stop()" onmouseover="semantify_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='semantify_image'>
        <img src='images/semantify.jpg' width=100%>
      </div>
      <img src='images/semantify.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function semantify_start() {
        document.getElementById('semantify_image').style.opacity = "1";
      }

      function semantify_stop() {
        document.getElementById('semantify_image').style.opacity = "0";
      }
      semantify_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://omergral.github.io/Semantify/">
      <span class="papertitle">Semantify: Simplifying the Control of 3D Morphable Models using CLIP</span>
    </a>
    <br>
    <a href="https://omergral.github.io/">Omer Gralnik</a>,
    <strong>Guy Gafni</strong>,
    <a href="https://www.idc.ac.il/en/pages/faculty.aspx?username=shamir">Ariel Shamir</a>
    <br>
    <em>ICCV</em>, 2023
    <br>
    <a href="https://omergral.github.io/Semantify/">project page</a>
    /
    <a href="https://arxiv.org/abs/2308.07415">arXiv</a>
    <br>
    <a href="https://github.com/Omergral/Semantify" style="text-decoration: none;">
      <img src="https://img.shields.io/github/stars/Omergral/Semantify?style=social" alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
      <img src="https://img.shields.io/github/forks/Omergral/Semantify?style=social" alt="GitHub forks" style="vertical-align: middle;">
    </a>
    <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PATfNhwAAAAJ&citation_for_view=PATfNhwAAAAJ:d1gkVwhDpl0C" style="text-decoration: none; margin-left: 5px;" id="semantify-citation-link">
      <img src="https://img.shields.io/badge/Citations-Loading-blue" alt="Citations" style="vertical-align: middle;" id="semantify-citation-badge">
    </a>
    <p></p>
    <p>
    A self-supervised method that utilizes the power of CLIP VLM to simplify the control of 3D morphable models, by learning a mapping from natural language to a 3DMM basis.
    </p>
  </td>
</tr>

<tr onmouseout="facial4d_stop()" onmouseover="facial4d_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='facial4d_image'>
        <img src='images/facial4d.jpg' width=100%>
      </div>
      <img src='images/facial4d.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function facial4d_start() {
        document.getElementById('facial4d_image').style.opacity = "1";
      }

      function facial4d_stop() {
        document.getElementById('facial4d_image').style.opacity = "0";
      }
      facial4d_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://gafniguy.github.io/4D-Facial-Avatars/">
      <span class="papertitle">NeRFace: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction</span>
    </a>
    <br>
    <strong>Guy Gafni</strong>,
    <a href="https://justusthies.github.io/">Justus Thies</a>,
    <a href="https://zollhoefer.com/">Michael Zollh√∂fer</a>,
    <a href="https://www.niessnerlab.org/members/matthias-niessner/profile.html">Matthias Nie√üner</a>
    <br>
    <em>CVPR (Oral)</em>, 2021
    <br>
    <a href="https://gafniguy.github.io/4D-Facial-Avatars/">project page</a>
    /
    <a href="https://arxiv.org/abs/2012.03065">arXiv</a>
    <br>
    <a href="https://github.com/gafniguy/4D-Facial-Avatars" style="text-decoration: none;">
      <img src="https://img.shields.io/github/stars/gafniguy/4D-Facial-Avatars?style=social" alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
      <img src="https://img.shields.io/github/forks/gafniguy/4D-Facial-Avatars?style=social" alt="GitHub forks" style="vertical-align: middle;">
    </a>
    <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PATfNhwAAAAJ&citation_for_view=PATfNhwAAAAJ:u5HHmVD_uO8C" style="text-decoration: none; margin-left: 5px;" id="facial4d-citation-link">
      <img src="https://img.shields.io/badge/Citations-Loading-blue" alt="Citations" style="vertical-align: middle;" id="facial4d-citation-badge">
    </a>
    <p></p>
    <p>
    The first method to combine NeRFs with 3DMM to reconstruct and re-render human faces.
    </p>
  </td>
</tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:8px;width:12%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:88%;vertical-align:center">
                Reviewer for ICCV, CVPR, SIGGRAPH and SIGGRAPH ASIA
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:8px;width:12%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:88%;vertical-align:center">
                Introduction to Deep Learning (TU Munich)
                <br>
                Seminar on Neural Radiance Fields (TU Munich)
                <br>
                Calculus 3 (TAU)
              </td>
            </tr>
            
            <tr>
              <td align="center" style="padding:8px;width:12%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Additional Stuff</h2>
								 </div>
              </td>
              <td style="padding:8px;width:88%;vertical-align:center">
                <ul style="margin:0; padding-left:20px;">
                  <li>Common-Ground AI (Acq. by Apple in 2024) - Advisor to the CTO and R&D teams, guiding the research roadmap for 3D human reconstruction from mobile devices: faces/heads, meshing, neural rendering, dynamic animation of textures, hair reconstruction, and re-animation of the reconstructed geometry in real-time.
                  </li>
                  <li>As a master student at TUM, I worked on neural rendering of point clouds for novel view synthesis (2019), and face replacement using CycleGAN in texture space of 3DMMs (2018)</li>
                  <li>I obtained my Bsc in Mathematics and Computer Science from Tel Aviv University (2017)</li>
                  <li>Worked at PTC on Subdivision Surfaces and processing of its control meshes, contributing to the Creo CAD software (2017)</li>

                  
                </ul>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a> from Jon Barron. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
    <script>
      // Function to fetch citation count from Google Scholar
      async function fetchCitationCount(citationId, badgeId) {
        try {
          // Use a CORS proxy to fetch Google Scholar page
          const proxyUrl = 'https://api.allorigins.win/get?url=';
          const scholarUrl = encodeURIComponent(`https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PATfNhwAAAAJ&citation_for_view=${citationId}`);
          
          const response = await fetch(proxyUrl + scholarUrl);
          const data = await response.json();
          const html = data.contents;
          
          // Extract citation count using regex
          const match = html.match(/Cited by (\d+)/);
          if (match && match[1]) {
            const count = match[1];
            const badge = document.getElementById(badgeId);
            if (badge) {
              badge.src = `https://img.shields.io/badge/Citations-${count}-blue`;
              badge.alt = `Citations: ${count}`;
            }
          }
        } catch (error) {
          console.error('Error fetching citation count:', error);
          // Fallback: show "N/A" if fetch fails
          const badge = document.getElementById(badgeId);
          if (badge) {
            badge.src = 'https://img.shields.io/badge/Citations-N%2FA-lightgrey';
            badge.alt = 'Citations: N/A';
          }
        }
      }
      
      // Fetch citation counts when page loads
      window.addEventListener('DOMContentLoaded', function() {
        // Semantify: PATfNhwAAAAJ:d1gkVwhDpl0C
        fetchCitationCount('PATfNhwAAAAJ:d1gkVwhDpl0C', 'semantify-citation-badge');
        // 4D Facial Avatars: PATfNhwAAAAJ:u5HHmVD_uO8C
        fetchCitationCount('PATfNhwAAAAJ:u5HHmVD_uO8C', 'facial4d-citation-badge');
      });
    </script>
  </body>
</html>
